{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8556d325-5906-4b57-812e-b8924396dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 31 - For Proposed Multimodal Fusion - Normailized Power Calculation - For Results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a890f99b-364f-4dd3-93c6-ac1b561c9e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import scipy.io as scipyio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf67ed8-4d0f-4d67-b695-82e240b2a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute path of the folder containing the units' folders and scenarioX.csv\n",
    "scenario_folder = r'C:\\Users\\Baqer\\Desktop\\V2X_CNN_All\\Scenario31_64-Beams\\scenario31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99da7039-e317-4c68-8fdb-e27cab70aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically fetch CSV (the only csv in folder)\n",
    "try:\n",
    "    csv_file = [f for f in os.listdir(scenario_folder) if f == 'best_epoch_Test.csv'][0]\n",
    "    csv_path = os.path.join(scenario_folder, csv_file)\n",
    "except IndexError:\n",
    "    print(\"best_epoch_Test.csv not found in the scenario folder.\")\n",
    "\n",
    "dataframe = pd.read_csv(csv_path)\n",
    "print(f'Columns: {dataframe.columns.values}')\n",
    "print(f'Number of Rows: {dataframe.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc376ab9-3077-4af5-8c83-ea55cfbe361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BEAMS = 64\n",
    "n_samples = 100\n",
    "pwr_rel_paths = dataframe['original_unit1_pwr1'].values\n",
    "pwrs_array = np.zeros((n_samples, N_BEAMS))\n",
    "\n",
    "for sample_idx in tqdm(range(n_samples)):\n",
    "    pwr_abs_path = os.path.join(scenario_folder, pwr_rel_paths[sample_idx])\n",
    "    pwrs_array[sample_idx] = np.loadtxt(pwr_abs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f3c265-a6b8-4524-ac2e-1ec59c37f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_samples = [0, 2]\n",
    "beam_idxs = np.arange(N_BEAMS) + 1\n",
    "pwrs_array_selected = pwrs_array[selected_samples].T\n",
    "\n",
    "for i, sample in enumerate(selected_samples):\n",
    "    print(f\"Sample {sample}:\\n{pwrs_array_selected[:, i]}\")\n",
    "\n",
    "# Plotting the graph (optional)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(beam_idxs, pwrs_array_selected)\n",
    "plt.legend([f'Sample {i}' for i in selected_samples])\n",
    "plt.xlabel('Beam indices')\n",
    "plt.ylabel('Power')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e17d13-8c15-46a3-9e98-924a9aee5214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    csv_file = [f for f in os.listdir(scenario_folder) if f == 'best_epoch_Test.csv'][0]\n",
    "    csv_path = os.path.join(scenario_folder, csv_file)\n",
    "except IndexError:\n",
    "    print(\"best_epoch_Test.csv.csv not found in the scenario folder.\")\n",
    "\n",
    "dataframe = pd.read_csv(csv_path)\n",
    "\n",
    "# Select the columns from top3_pred to top15_pred\n",
    "selected_columns = dataframe.columns[dataframe.columns.get_loc('top3_pred'):dataframe.columns.get_loc('top15_pred')+1]\n",
    "\n",
    "# Create a new DataFrame with the mentioned columns at the beginning\n",
    "new_dataframe = pd.DataFrame()\n",
    "new_dataframe['index'] = dataframe['index']\n",
    "new_dataframe['link_status'] = dataframe['link_status']\n",
    "new_dataframe['original_unit1_pwr1'] = dataframe['original_unit1_pwr1']\n",
    "new_dataframe['top1_pred'] = dataframe['top1_pred']\n",
    "\n",
    "# Split the remaining columns and add them to the new DataFrame\n",
    "for i, column in enumerate(selected_columns[::-1], 1):\n",
    "    new_columns = dataframe[column].astype(str).str.strip('[]').str.split(', ').apply(lambda x: pd.Series(x))\n",
    "    new_columns.columns = [f'{column}_split_{j}' for j in range(len(new_columns.columns), 0, -1)]\n",
    "    new_dataframe = pd.concat([new_columns, new_dataframe], axis=1)\n",
    "\n",
    "# Reorder the columns\n",
    "columns_order = ['index', 'link_status', 'original_unit1_pwr1', 'top1_pred'] + list(new_dataframe.columns[:-4])\n",
    "new_dataframe = new_dataframe[columns_order]\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "new_dataframe.to_csv('splitted.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d001d2-6872-4719-ab21-2d6c5d713c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Absolute path of the folder containing the units' folders and splitted.csv\n",
    "scenario_folder = r'C:\\Users\\Baqer\\Desktop\\V2X_CNN_All\\Scenario31_64-Beams\\Power_Calculations-Proposed'\n",
    "scenario_folder_main = r'C:\\Users\\Baqer\\Desktop\\V2X_CNN_All\\Scenario31_64-Beams\\scenario31'\n",
    "# Read the 'splitted.csv' file into a DataFrame\n",
    "csv_file = 'splitted.csv'\n",
    "csv_path = os.path.join(scenario_folder, csv_file)\n",
    "dataframe = pd.read_csv(csv_path)\n",
    "\n",
    "# Columns to keep in the desired order\n",
    "columns_order = ['index', 'original_unit1_pwr1', 'link_status', 'power_link_status', 'power_top1_pred'] + [col for col in dataframe.columns if col not in ['index', 'original_unit1_pwr1', 'link_status', 'power_link_status']]\n",
    "\n",
    "N_BEAMS = 64\n",
    "n_samples = dataframe.shape[0]\n",
    "pwr_rel_paths = dataframe['original_unit1_pwr1'].values\n",
    "pwrs_array = np.zeros((n_samples, N_BEAMS))\n",
    "\n",
    "# Load the power data for each sample\n",
    "for sample_idx in range(n_samples):\n",
    "    pwr_abs_path = os.path.join(scenario_folder_main, pwr_rel_paths[sample_idx])\n",
    "    pwrs_array[sample_idx] = np.loadtxt(pwr_abs_path)\n",
    "\n",
    "# Iterate over the rows of the DataFrame and extract values\n",
    "extracted_values = []\n",
    "extracted_values_2 = []\n",
    "for index, row in dataframe.iterrows():\n",
    "    sample_idx = index  # Use the row index as the sample index\n",
    "    list_index = row['link_status']  \n",
    "    list_index_2 = row['top1_pred']\n",
    "    \n",
    "    # Adjust the list index by subtracting 1 to match the zero-based indexing in the power array\n",
    "    adjusted_index = list_index - 1\n",
    "    adjusted_index_2 = list_index_2 - 1\n",
    "    \n",
    "    # Check if the adjusted list index is within the range of the power array\n",
    "    if 0 <= adjusted_index < pwrs_array.shape[1]:\n",
    "        value = pwrs_array[sample_idx, adjusted_index]  # Get the corresponding element from the power array\n",
    "        extracted_values.append(value)\n",
    "    else:\n",
    "        extracted_values.append(np.nan)\n",
    "    if 0 <= adjusted_index_2 < pwrs_array.shape[1]:\n",
    "        value_2 = pwrs_array[sample_idx, adjusted_index_2]\n",
    "        extracted_values_2.append(value_2)\n",
    "    else:\n",
    "        extracted_values_2.append(np.nan)\n",
    "\n",
    "# Add the extracted values as a new column named 'power_link_status' beside 'link_status'\n",
    "dataframe.insert(dataframe.columns.get_loc('link_status') + 1, 'power_link_status', extracted_values)\n",
    "dataframe.insert(dataframe.columns.get_loc('top1_pred') + 1, 'power_top1_pred', extracted_values_2)\n",
    "# Reorder the columns according to the defined order\n",
    "dataframe = dataframe[columns_order]\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_csv_path = os.path.join(scenario_folder, 'power.rough.csv')\n",
    "dataframe.to_csv(output_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd936d75-35c3-45fa-89f3-797144910587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Absolute path of the folder containing the units' folders and splitted.csv\n",
    "scenario_folder = r'C:\\Users\\Baqer\\Desktop\\V2X_CNN_All\\Scenario31_64-Beams\\Power_Calculations-Proposed'\n",
    "scenario_folder_main = r'C:\\Users\\Baqer\\Desktop\\V2X_CNN_All\\Scenario31_64-Beams\\scenario31'\n",
    "# Read the 'splitted.csv' file into a DataFrame\n",
    "csv_file = 'splitted.csv'\n",
    "csv_path = os.path.join(scenario_folder, csv_file)\n",
    "dataframe = pd.read_csv(csv_path)\n",
    "\n",
    "# Columns to keep in the desired order\n",
    "columns_order = ['index', 'original_unit1_pwr1', 'link_status'] + \\\n",
    "    [col for col in dataframe.columns if col not in ['index', 'original_unit1_pwr1', 'link_status']]\n",
    "\n",
    "N_BEAMS = 64\n",
    "n_samples = dataframe.shape[0]\n",
    "pwr_rel_paths = dataframe['original_unit1_pwr1'].values\n",
    "pwrs_array = np.zeros((n_samples, N_BEAMS))\n",
    "\n",
    "# Load the power data for each sample\n",
    "for sample_idx in range(n_samples):\n",
    "    pwr_abs_path = os.path.join(scenario_folder_main, pwr_rel_paths[sample_idx])\n",
    "    pwrs_array[sample_idx] = np.loadtxt(pwr_abs_path)\n",
    "\n",
    "# Create a new DataFrame to hold the power columns\n",
    "power_dataframe = pd.DataFrame()\n",
    "\n",
    "# Iterate over the rows of the DataFrame and extract values\n",
    "for index, row in dataframe.iterrows():\n",
    "    sample_idx = index  # Use the row index as the sample index\n",
    "    list_index = row['link_status']\n",
    "    \n",
    "    # Adjust the list index by subtracting 1 to match the zero-based indexing in the power array\n",
    "    adjusted_index = list_index - 1\n",
    "    \n",
    "    # Check if the adjusted list index is within the range of the power array\n",
    "    if 0 <= adjusted_index < pwrs_array.shape[1]:\n",
    "        value = pwrs_array[sample_idx, adjusted_index]  # Get the corresponding element from the power array\n",
    "        power_dataframe.at[index, 'power_link_status'] = value\n",
    "\n",
    "# Iterate over the split string columns and extract values\n",
    "for column in dataframe.columns[dataframe.columns.str.contains('split')]:\n",
    "    for index, row in dataframe.iterrows():\n",
    "        sample_idx = index  # Use the row index as the sample index\n",
    "        split_value = row[column]\n",
    "        adjusted_index = split_value - 1\n",
    "        \n",
    "        # Check if the adjusted index is within the range of the power array\n",
    "        if 0 <= adjusted_index < pwrs_array.shape[1]:\n",
    "            value = pwrs_array[sample_idx, adjusted_index]  # Get the corresponding element from the power array\n",
    "            power_column_name = f'power_{column}'\n",
    "            power_dataframe.at[index, power_column_name] = value\n",
    "\n",
    "# Save the power DataFrame to a new CSV file\n",
    "output_csv_path = os.path.join(scenario_folder, 'power-rough2.csv')\n",
    "power_dataframe.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file without the power columns\n",
    "dataframe_without_power = dataframe.drop(columns=[col for col in dataframe.columns if 'split' in col])\n",
    "output_csv_path_without_power = os.path.join(scenario_folder, 'data_top-1_link_status.csv')\n",
    "dataframe_without_power.to_csv(output_csv_path_without_power, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e8d33-b850-4ccb-ba31-8407c7f339fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# Absolute path of the folder containing the power rough csv files\n",
    "scenario_folder = r'C:\\Users\\Baqer\\Desktop\\V2X_CNN_All\\Scenario31_64-Beams\\Power_Calculations-Proposed'\n",
    "\n",
    "# Read the 'power.rough.csv' and 'power-rough2.csv' files into DataFrames\n",
    "power_csv_file = 'power.rough.csv'\n",
    "power_csv_path = os.path.join(scenario_folder, power_csv_file)\n",
    "power_dataframe = pd.read_csv(power_csv_path)\n",
    "\n",
    "power9_csv_file = 'power-rough2.csv'\n",
    "power9_csv_path = os.path.join(scenario_folder, power9_csv_file)\n",
    "power9_dataframe = pd.read_csv(power9_csv_path)\n",
    "\n",
    "# Merge the power and power9 DataFrames based on the index\n",
    "merged_dataframe = pd.merge(power_dataframe, power9_dataframe, left_index=True, right_index=True)\n",
    "\n",
    "# Remove the \"power_link_status_y\" column\n",
    "merged_dataframe.drop(columns='power_link_status_y', inplace=True)\n",
    "\n",
    "# Rename the \"power_link_status_x\" column to \"power_link_status\"\n",
    "merged_dataframe.rename(columns={'power_link_status_x': 'power_link_status'}, inplace=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "output_csv_path = os.path.join(scenario_folder, '0final_results.csv')\n",
    "merged_dataframe.to_csv(output_csv_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
